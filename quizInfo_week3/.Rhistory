ggplot(samples, aes(x = Concentration, y = Absorbance, col = type, shape = Keep, size = 2)) +
scale_shape_manual(values = c(4, 16)) +
geom_point() +
geom_abline(aes(intercept = fit()$coefficients[1],
slope = fit()$coefficients[2],
size = 1.5,
alpha = 0.5)) +
guides(alpha = F, size = F) +
theme_set(theme_grey(base_size = 15))
})
output$sampTable <- renderTable({
samples()
})
output$sampSum <- renderTable({
sampleSummary()
})
output$plateHeat <- renderPlot({
temp <- absorbances()
colnames(temp) <- sprintf('%0.2d', 1:ncol(temp))
temp <- cbind(`Row` = LETTERS[1:8], temp) %>%
gather(key = "Column", value = "abs", -`Row`) %>%
dplyr::mutate(Row = fct_rev(.$Row))
ggplot(temp, aes(Column, Row)) +
geom_tile(aes(fill = abs), color = "white") +
geom_text(aes(label = round(abs, 2))) +
scale_fill_gradient(low = "lightyellow", high = "mediumpurple3") +
theme_classic() +
theme_set(theme_classic(base_size = 15)) +
theme(legend.position = "none",
axis.title.x = element_blank(),
axis.title.y = element_blank())
})
}
shinyApp(ui, server)
# quantifyProtein.R
#
# What this script does:
# * Quantifies protein from plate reader files
# * Calculates buffer required for a custom dilution concentration and volume
#
# What this script does not (yet) do:
# * Allow for irregular plate layouts
# TODO
# Take std range as an argument for where the standards were placed
# Would be much easier with a GUI
# Ascending or descending std arguments
# Simple setting of corners for non-standard standard placement
# Allow to specify number of samples (Auto drop option (default ON))
# Only present necessary information. Stow away the rest in an 'advanced' tab
# ---- Prepare Workspace ----
library(tidyverse)
library(readxl)
library(shiny)
# ---- Define Functions ----
findMean <- function(df){
test <- df$absorbance %>%
dist() %>%
hclust()
potOutlierPos <- test$merge[nrow(df) - 1, 1] %>%
abs()
potOutlier <- df$absorbance[potOutlierPos]
sansOutlier <- df$absorbance[-potOutlierPos]
meanSans <- mean(sansOutlier)
sdSans <- sd(sansOutlier)
myDat <- list(df$concentration, df$absorbance, meanSans, sdSans)
}
# ---- Shiny UI ----
ui <- fluidPage(
titlePanel("Protein Quantification"),
sidebarLayout(
sidebarPanel(
fileInput("file", "Upload SpectraMAX Excel File"),
radioButtons("sampleOrientation", "Sample Orientation", choices = c("Horizontal" = "horiz", "Vertical" = "vert")),
numericInput("targetConc", "Target Concentration Before Sample Buffer (mg/mL)", 1.2),
numericInput("targetVol", "Target Volume Before Sample Buffer (uL)", 60)
),
mainPanel(
tabsetPanel(
tabPanel("Plate Heatmap", plotOutput("plateHeat")),
tabPanel("Standard Plot", plotOutput("stdPlot")),
tabPanel("Standard Table", tableOutput("stdTable")),
tabPanel("Sample Table", tableOutput("sampTable")),
tabPanel("Dilution Calculations", tableOutput("sampSum"))
),
),
),
)
# ---- Shiny Server ----
server <- function(input, output) {
absorbances <- eventReactive(input$file, {
if (grepl("x$",input$file$datapath)) {
temp <- read_xlsx(input$file$datapath)
}
else {
temp <- read_xls(input$file$datapath)
}
temp[,-1]
})
plateHeatmap <- eventReactive(input$file, {
temp <- absorbances()
colnames(temp) <- c(as.character(1:12))
temp <- rbind(LETTERS[1:8], temp) %>%
gather(key = "column", value = "absorbance", temp[,2:13])
})
standards <- eventReactive({input$sampleOrientation
input$file}, {
temp <- switch(input$sampleOrientation,
horiz = absorbances()[1:3,1:7],
vert = t(absorbances()[1:7,1:3]))
colnames(temp) <- c("1", "2", "3", "4", "5", "6", "7")
standards <- temp %>%
as_tibble() %>%
gather(key = "standard", value = "absorbance") %>%
add_column(concentration = c(0, 0, 0, rep(.125*2^(0:5), each = 3))) %>%
group_by(standard) %>%
group_nest() %>%
dplyr::mutate(meanWithoutOutlier = map(data, findMean)) %>%
dplyr::select(-data) %>%
unnest() %>%
dplyr::mutate(cols = rep(c("Concentration", "Absorbance", "Adjusted Mean", "SD"), nrow(.)/4)) %>%
spread(key = cols, value = meanWithoutOutlier) %>%
unnest(Absorbance, Concentration, .drop = F) %>%
unnest() %>%
mutate(Keep = case_when(`Adjusted Mean` - 3 * SD < Absorbance & `Adjusted Mean` + 3 * SD > Absorbance ~ T, T ~ F)) %>%
dplyr::select(-SD)
})
fit <- eventReactive({input$sampleOrientation
input$file}, {
standards <- standards() %>%
filter(Keep)
lm(Absorbance ~ Concentration, standards)
})
samples <- eventReactive({input$sampleOrientation
input$file}, {
temp0 <- setNames(absorbances(), rep("Sample", times = 12))
temp <- switch(input$sampleOrientation,
horiz = cbind(temp0[1:3, 8:12], temp0[4:6, 1:12]),
vert = as_tibble(t(rbind(temp0[8, 1:3], temp0[1:8, 4:6], temp0[1:8, 7:9], temp0[1:8, 10:12]))))
temp <- setNames(temp, paste("Sample", sprintf('%0.2d', 1:ncol(temp))))
samples <- temp %>%
as_tibble() %>%
gather(key = "Sample", value = "absorbance") %>%
add_column(concentration = 0) %>%
group_by(Sample) %>%
group_nest() %>%
dplyr::mutate(meanWithoutOutlier = map(data, findMean)) %>%
dplyr::select(-data) %>%
unnest() %>%
dplyr::mutate(cols = rep(c("Concentration", "Absorbance", "Adjusted Mean", "SD"), nrow(.)/4)) %>%
spread(key = cols, value = meanWithoutOutlier) %>%
unnest(Absorbance, Concentration, .drop = F) %>%
unnest() %>%
mutate(Keep = case_when(`Adjusted Mean` - 3*SD < Absorbance & `Adjusted Mean` + 3*SD > Absorbance ~ T, T ~ F)) %>%
mutate(Concentration = (`Adjusted Mean` - fit()$coefficients[1])/fit()$coefficients[2]) %>%
dplyr::select(-SD)
})
sampleSummary <- eventReactive({input$sampleOrientation
input$file
input$targetConc
input$targetVol}, {
temp <- unique(samples()[,c(1,4)]) %>%
add_column(`[Target] (mg/mL)` = input$targetConc, `Target Volume (uL)` = input$targetVol) %>%
mutate(`Lysate to Add (uL)` = `[Target] (mg/mL)` * `Target Volume (uL)`/Concentration,
`RIPA to Add (uL)` = `Target Volume (uL)` - `Lysate to Add`)
})
output$stdTable <- renderTable({
standards()
})
output$stdPlot <- renderPlot({
samples <- cbind(samples()[,c(2,4,5)], type = "Sample")
standards <- cbind(standards()[,c(2,4,5)], type = "Standard")
samples <- rbind(samples, standards)
ggplot(samples, aes(x = Concentration, y = Absorbance, col = type, shape = Keep, size = 2)) +
scale_shape_manual(values = c(4, 16)) +
geom_point() +
geom_abline(aes(intercept = fit()$coefficients[1],
slope = fit()$coefficients[2],
size = 1.5,
alpha = 0.5)) +
guides(alpha = F, size = F) +
theme_set(theme_grey(base_size = 15))
})
output$sampTable <- renderTable({
samples()
})
output$sampSum <- renderTable({
sampleSummary()
})
output$plateHeat <- renderPlot({
temp <- absorbances()
colnames(temp) <- sprintf('%0.2d', 1:ncol(temp))
temp <- cbind(`Row` = LETTERS[1:8], temp) %>%
gather(key = "Column", value = "abs", -`Row`) %>%
dplyr::mutate(Row = fct_rev(.$Row))
ggplot(temp, aes(Column, Row)) +
geom_tile(aes(fill = abs), color = "white") +
geom_text(aes(label = round(abs, 2))) +
scale_fill_gradient(low = "lightyellow", high = "mediumpurple3") +
theme_classic() +
theme_set(theme_classic(base_size = 15)) +
theme(legend.position = "none",
axis.title.x = element_blank(),
axis.title.y = element_blank())
})
}
shinyApp(ui, server)
# quantifyProtein.R
#
# What this script does:
# * Quantifies protein from plate reader files
# * Calculates buffer required for a custom dilution concentration and volume
#
# What this script does not (yet) do:
# * Allow for irregular plate layouts
# TODO
# Take std range as an argument for where the standards were placed
# Would be much easier with a GUI
# Ascending or descending std arguments
# Simple setting of corners for non-standard standard placement
# Allow to specify number of samples (Auto drop option (default ON))
# Only present necessary information. Stow away the rest in an 'advanced' tab
# ---- Prepare Workspace ----
library(tidyverse)
library(readxl)
library(shiny)
# ---- Define Functions ----
findMean <- function(df){
test <- df$absorbance %>%
dist() %>%
hclust()
potOutlierPos <- test$merge[nrow(df) - 1, 1] %>%
abs()
potOutlier <- df$absorbance[potOutlierPos]
sansOutlier <- df$absorbance[-potOutlierPos]
meanSans <- mean(sansOutlier)
sdSans <- sd(sansOutlier)
myDat <- list(df$concentration, df$absorbance, meanSans, sdSans)
}
# ---- Shiny UI ----
ui <- fluidPage(
titlePanel("Protein Quantification"),
sidebarLayout(
sidebarPanel(
fileInput("file", "Upload SpectraMAX Excel File"),
radioButtons("sampleOrientation", "Sample Orientation", choices = c("Horizontal" = "horiz", "Vertical" = "vert")),
numericInput("targetConc", "Target Concentration Before Sample Buffer (mg/mL)", 1.2),
numericInput("targetVol", "Target Volume Before Sample Buffer (uL)", 60)
),
mainPanel(
tabsetPanel(
tabPanel("Plate Heatmap", plotOutput("plateHeat")),
tabPanel("Standard Plot", plotOutput("stdPlot")),
tabPanel("Standard Table", tableOutput("stdTable")),
tabPanel("Sample Table", tableOutput("sampTable")),
tabPanel("Dilution Calculations", tableOutput("sampSum"))
),
),
),
)
# ---- Shiny Server ----
server <- function(input, output) {
absorbances <- eventReactive(input$file, {
if (grepl("x$",input$file$datapath)) {
temp <- read_xlsx(input$file$datapath)
}
else {
temp <- read_xls(input$file$datapath)
}
temp[,-1]
})
plateHeatmap <- eventReactive(input$file, {
temp <- absorbances()
colnames(temp) <- c(as.character(1:12))
temp <- rbind(LETTERS[1:8], temp) %>%
gather(key = "column", value = "absorbance", temp[,2:13])
})
standards <- eventReactive({input$sampleOrientation
input$file}, {
temp <- switch(input$sampleOrientation,
horiz = absorbances()[1:3,1:7],
vert = t(absorbances()[1:7,1:3]))
colnames(temp) <- c("1", "2", "3", "4", "5", "6", "7")
standards <- temp %>%
as_tibble() %>%
gather(key = "standard", value = "absorbance") %>%
add_column(concentration = c(0, 0, 0, rep(.125*2^(0:5), each = 3))) %>%
group_by(standard) %>%
group_nest() %>%
dplyr::mutate(meanWithoutOutlier = map(data, findMean)) %>%
dplyr::select(-data) %>%
unnest() %>%
dplyr::mutate(cols = rep(c("Concentration", "Absorbance", "Adjusted Mean", "SD"), nrow(.)/4)) %>%
spread(key = cols, value = meanWithoutOutlier) %>%
unnest(Absorbance, Concentration, .drop = F) %>%
unnest() %>%
mutate(Keep = case_when(`Adjusted Mean` - 3 * SD < Absorbance & `Adjusted Mean` + 3 * SD > Absorbance ~ T, T ~ F)) %>%
dplyr::select(-SD)
})
fit <- eventReactive({input$sampleOrientation
input$file}, {
standards <- standards() %>%
filter(Keep)
lm(Absorbance ~ Concentration, standards)
})
samples <- eventReactive({input$sampleOrientation
input$file}, {
temp0 <- setNames(absorbances(), rep("Sample", times = 12))
temp <- switch(input$sampleOrientation,
horiz = cbind(temp0[1:3, 8:12], temp0[4:6, 1:12]),
vert = as_tibble(t(rbind(temp0[8, 1:3], temp0[1:8, 4:6], temp0[1:8, 7:9], temp0[1:8, 10:12]))))
temp <- setNames(temp, paste("Sample", sprintf('%0.2d', 1:ncol(temp))))
samples <- temp %>%
as_tibble() %>%
gather(key = "Sample", value = "absorbance") %>%
add_column(concentration = 0) %>%
group_by(Sample) %>%
group_nest() %>%
dplyr::mutate(meanWithoutOutlier = map(data, findMean)) %>%
dplyr::select(-data) %>%
unnest() %>%
dplyr::mutate(cols = rep(c("Concentration", "Absorbance", "Adjusted Mean", "SD"), nrow(.)/4)) %>%
spread(key = cols, value = meanWithoutOutlier) %>%
unnest(Absorbance, Concentration, .drop = F) %>%
unnest() %>%
mutate(Keep = case_when(`Adjusted Mean` - 3*SD < Absorbance & `Adjusted Mean` + 3*SD > Absorbance ~ T, T ~ F)) %>%
mutate(Concentration = (`Adjusted Mean` - fit()$coefficients[1])/fit()$coefficients[2]) %>%
dplyr::select(-SD)
})
sampleSummary <- eventReactive({input$sampleOrientation
input$file
input$targetConc
input$targetVol}, {
temp <- unique(samples()[,c(1,4)]) %>%
add_column(`[Target] (mg/mL)` = input$targetConc, `Target Volume (uL)` = input$targetVol) %>%
mutate(`Lysate to Add (uL)` = `[Target] (mg/mL)` * `Target Volume (uL)`/Concentration,
`RIPA to Add (uL)` = `Target Volume (uL)` - `Lysate to Add (uL)`)
})
output$stdTable <- renderTable({
standards()
})
output$stdPlot <- renderPlot({
samples <- cbind(samples()[,c(2,4,5)], type = "Sample")
standards <- cbind(standards()[,c(2,4,5)], type = "Standard")
samples <- rbind(samples, standards)
ggplot(samples, aes(x = Concentration, y = Absorbance, col = type, shape = Keep, size = 2)) +
scale_shape_manual(values = c(4, 16)) +
geom_point() +
geom_abline(aes(intercept = fit()$coefficients[1],
slope = fit()$coefficients[2],
size = 1.5,
alpha = 0.5)) +
guides(alpha = F, size = F) +
theme_set(theme_grey(base_size = 15))
})
output$sampTable <- renderTable({
samples()
})
output$sampSum <- renderTable({
sampleSummary()
})
output$plateHeat <- renderPlot({
temp <- absorbances()
colnames(temp) <- sprintf('%0.2d', 1:ncol(temp))
temp <- cbind(`Row` = LETTERS[1:8], temp) %>%
gather(key = "Column", value = "abs", -`Row`) %>%
dplyr::mutate(Row = fct_rev(.$Row))
ggplot(temp, aes(Column, Row)) +
geom_tile(aes(fill = abs), color = "white") +
geom_text(aes(label = round(abs, 2))) +
scale_fill_gradient(low = "lightyellow", high = "mediumpurple3") +
theme_classic() +
theme_set(theme_classic(base_size = 15)) +
theme(legend.position = "none",
axis.title.x = element_blank(),
axis.title.y = element_blank())
})
}
shinyApp(ui, server)
runApp('quantifyProtein.R')
?grep
install.packages(tidyverse)
install.packages('tidyverse')
find.package('tidyverse')
library('tidyverse')
library(tidyverse)
?download.file
getwd()
# notepad for the Week 3 quiz in "Getting and Cleaning Data"
# load packages
library(tidyverse)
# load in data
filename <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file('~/GettingAndCleaningData/quizInfo')
setwd('~/GettingandCleaningData/quizInfo')
Idaho_survey <- read.csv(filename)
View(Idaho_survey)
View(Idaho_survey)
?download.file
# notepad for the Week 3 quiz in "Getting and Cleaning Data"
# load packages
library(tidyverse)
# load in data
filename <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(filename, '~/GettingAndCleaningData/quizInfo/ACS_community-survey_Idaho')
setwd('~/GettingandCleaningData/quizInfo')
Idaho_survey <- read.csv('ACS_community-survey_Idaho')
View(Idaho_survey)
rm(list=ls())
# notepad for the Week 3 quiz in "Getting and Cleaning Data"
# load packages
library(tidyverse)
# load in data
filename <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(filename, '~/GettingAndCleaningData/quizInfo/ACS_community-survey_Idaho')
setwd('~/GettingandCleaningData/quizInfo')
Idaho_survey <- read_csv('ACS_community-survey_Idaho')
View(Idaho_survey)
# subset data based on acreage and
#agricultureLogical <-
Idaho_survey[[RT]]
Idaho_survey[['ACR']]
Idaho_survey[['ACR']][['AGS']]
Idaho_survey[[['ACR','AGS']]
Idaho_survey[[['ACR','AGS']]
Idaho_survey[[['ACR','AGS']]]
# subset data based on acreage (greater than 10 acres) and agricultural production value (over $10,000)
homes_subset <- select(Idaho_survey,'ACR','AGS')
View(homes_subset)
homes_subset_logical <- as.logical(homes_subset$ACR == 3,homes_subset$AGS == 6)
agricultureLogical <- which(homes_subset_logical)
homes_subset_logical <- as.logical(homes_subset$ACR == 3 && homes_subset$AGS == 6)
agricultureLogical <- which(homes_subset_logical)
,
homes_subset_logical <- as.logical(homes_subset$ACR == 3,homes_subset$AGS == 6)
agricultureLogical <- which(homes_subset_logical)
?select
agricultureLogical <- which(homes_subset$ACR == 3 $$ homes_subset$AGS == 6)
agricultureLogical <- which(homes_subset$ACR == 3 && homes_subset$AGS == 6)
which(agricultureLogical)
agricultureLogical <- as.logical(which(homes_subset$ACR == 3 && homes_subset$AGS == 6))
which(agricultureLogical)
sum(agricultureLogical)
homes_subset_logical <- as.logical(homes_subset$ACR == 3,homes_subset$AGS == 6)
View(homes_subset_logical)
homes_subset_logical <- as.logical(homes_subset$ACR == 3 && homes_subset$AGS == 6)
View(homes_subset_logical)
homes_subset_logical <- as.logical(homes_subset$ACR == 3 & homes_subset$AGS == 6)
View(homes_subset_logical)
which(homes_subset_logical)
which(homes_subset_logical)[1:3]
rm(list=ls())
# notepad for the Week 3 quiz in "Getting and Cleaning Data"
# load packages
library(tidyverse)
# load in data
filename <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(filename, '~/GettingAndCleaningData/quizInfo/ACS_community-survey_Idaho')
setwd('~/GettingandCleaningData/quizInfo')
Idaho_survey <- read_csv('ACS_community-survey_Idaho')
View(Idaho_survey)
# find households(rows) that fit quiz criteria (acreage over 10, sol over $10,000 of ag products)
homes_subset_logical <- as.logical(Idaho_survey$ACR == 3 & Idaho_survey$AGS == 6)
which(homes_subset_logical)[1:3]
find.package('jpeg')
library(jpeg)
fileUrl2 <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(fileUrl2, '~/GettingAndCleaningData/quizInfo/quizPicture')
picture <- readJPEG('~/GettingAndCleaningData/quizInfo/quizPicture',native = TRUE)
View(picture)
summary(picture)
View(picture)
class(picture)
pic <- readJPEG('~/GettingAndCleaningData/quizInfo/quizPicture',native = TRUE)
class(pic)
dim(pic)
rm(picture)
?summary
?quantile
quantile(pic)
quantile(pic, probs = seq(0.3,0.8))
quantile(pic, probs = seq(0.3, 0.8))
?seq
quantile(pic, probs = c(0.3,0.8))
quantile(pic, probs = c(0.2,0.7))
quantile(pic, probs = c(0.30,0.80))
fileUrl2 <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
#download.file(fileUrl2, '~/GettingAndCleaningData/quizInfo/quizPicture')
pic <- readJPEG(fileUrl2,native = TRUE)
quantile(pic, probs = c(0.30,0.80))
fileUrl2 <- 'http://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
#download.file(fileUrl2, '~/GettingAndCleaningData/quizInfo/quizPicture')
pic <- readJPEG(fileUrl2,native = TRUE)
quantile(pic, probs = c(0.30,0.80))
fileUrl2 <- 'http://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(fileUrl2, '~/GettingAndCleaningData/quizInfo/quizPicture')
pic <- readJPEG('~/GettingAndCleaningData/quizInfo/quizPicture',native = TRUE)
quantile(pic, probs = c(0.30,0.80))
pic <- readJPEG('~/GettingAndCleaningData/quizInfo/quizPicture',native = FALSE)
quantile(pic, probs = c(0.30,0.80))
View(pic)
pic <- readJPEG('~/GettingAndCleaningData/quizInfo/quizPicture',native = TRUE)
quantile(pic, probs = c(0.30,0.80))
View(pic)
pic2 <- as.matrix(pic)
View(pic2)
rm(pic2)
# QUESTION 2 ----------------------------------------------------------------
# what are the 30th and 80th quantiles of the readJPEG results of a picture of the instructor?
fileUrl2 <- 'http://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(fileUrl2, '~/GettingAndCleaningData/quizInfo/quizPicture', method = 'curl')
pic <- readJPEG('~/GettingAndCleaningData/quizInfo/quizPicture',native = TRUE)
quantile(pic, probs = c(0.30,0.80))
